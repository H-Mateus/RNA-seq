#+TITLE: EV RNA-seq
#+PROPERTY: header-args :dir ~/RNA_seq_mairead_2021-03-16 :exports code :results verbatim drawer :tangle ev_rnaseq_2021-03-17.sh :exports code :shebang "#!/bin/bash" :session rnaseq :eval no

* Experimental details
+ look for differentially expressed miRNAs in the different EV populations.

  We have 4 groups each with 4 doners and 1 FBS control.

| Condition                    | number of samples |
|------------------------------+-------------------|
| Normoxic Cells (Nor_Cell)    |                 4 |
| Normoxic EVs (Nor_EV)        |                 4 |
| Hypoxic EVs (Hyp_EV)         |                 4 |
| Normoxic/Primed EVs (N_P_EV) |                 4 |
| FBS control (FBS_EV)         |                 1 |

+ Instrument used: [[https://www.illumina.com/systems/sequencing-platforms/novaseq.html][Illumina seqencer: NovaSeq]] (should check model if correct)

#+begin_src bash

  pwd
  echo $PATH
  # set number of cores to one less than the total
  CORES=$(($(nproc) - 1))
  echo ${CORES}

#+end_src

* Software setup

Here we'll use [[https://docs.conda.io/en/latest/miniconda.html][miniconda]] to manage our software

#+begin_src bash :eval no

  # First we set up an environment for the project
  conda create -n rna_seq
  # Then we can install the software we need
  conda install python=3.8
  conda install -c bioconda fastqc
  conda install -c bioconda multiqc
  conda install -c bioconda cutadapt
  conda install -c bioconda trim-galore
  conda install salmon=1.4.0
#+end_src

#+begin_src bash

  # Then we activate the environment
  conda activate rna_seq
  # Then set up our channels - the last channel added is the highest priority
  conda config --add channels defaults
  conda config --add channels bioconda
  conda config --add channels conda-forge
#+end_src

Now let's check our conda status

#+begin_src bash

  # check conda info
  conda info
  # list packages
  conda list
#+end_src

* Raw data process

** FastQC

First, we should check the quality of the reads.
Here we're using [[https://www.bioinformatics.babraham.ac.uk/projects/fastqc/][fastqc]].

Move all the files into the same directory

#+begin_src bash

    # cd Raw
  ls -l -h
    for dir in ./Raw/*/
    do
        echo $dir
        mv ${dir}*.gz ~/RNA_seq_mairead_2021-03-16/Raw
    done

  ls -l -h
#+end_src

Run fastqc

#+begin_src bash

  # generate fastqc reports
  fastqc -o Raw/fastqc_reports Raw/*fastq.gz
#+end_src

As this generates a report for every file and manually looking through them all would be silly, we can use [[https://multiqc.info/docs/#running-multiqc][Multiqc]] to aggregate the report together.

#+begin_src bash

  # aggregate reports
  multiqc -o Raw/fastqc_reports Raw/fastqc_reports
#+end_src

** Trimming

Now we trim the reads using [[https://www.bioinformatics.babraham.ac.uk/projects/trim_galore/][=trim galore=]] which is a wrapper for [[https://cutadapt.readthedocs.io/en/stable/][Cutadapt]]
The University of Liverpool already trimmed the data, but we'll replicate this here to demonstrate.
They used cutadapt with =-O 3= and then [[https://github.com/najoshi/sickle/releases/tag/v1.2][Sickle]] to get a minimum pred score of 20, and remove reads less than 15 bp. in length.
Trim galore can autodetect adapter sequences, but we specify them here, again to match Liverpool.

#+begin_src bash

  # trim reads - set overlap to 3 and length to 15 to match Liverpool settings
  trim_galore -a " AGATCGGAAGAGCACACGTCT -a GATCGGAAGAGCACACGTCTGAACTCCAGTCAC -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC -a GATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT -a CTGTCTCTTATACACATCTCCGAGCCCACGAGAC -a CTGTCTCTTATACACATCTAGATGTGTATAAGAGACAG -a CGTAATAACTTCGTATAGCATACATTATACGAAGTTATACGA -a TCGTATAACTTCGTATAATGTATGCTATACGAAGTTATTACG" --stringency 3 --cores 8 --length 15 -o trimmed_manual Raw/*.fastq.gz
#+end_src

Trim Galore gives us these nice trimming reports, lests tidy them into their own directory.

#+begin_src bash

  # make directory for trimming reports
  mkdir trimmed_manual/trimming_reports
  # move reports
  mv trimmed_manual/*.txt trimmed_manual/trimming_reports
#+end_src

Now we check the quality of our trimmed files so we can compare to the raw data reports.

#+begin_src bash

  # generate fastqc reports on trimmed data
  fastqc -o trimmed_manual/fastqc_reports trimmed_manual/*.fq.gz
  # use multiqc
  multiqc -o trimmed_manual/fastqc_reports trimmed_manual/fastqc_reports
#+end_src

The multiqc report for the raw data can be found [[file:multiqc_reports/multiqc_report_raw.html][here]], and the trimmed data [[file:multiqc_reports/multiqc_report_trimmed.html][here]].

** Alignment

Now let's use [[https://salmon.readthedocs.io/en/latest/][salmon]] for aligmnent.
We'll use transcripts rather than the genome as this is is RNA sequencing data.
We use human transcripts from [[https://www.gencodegenes.org/][gencode]]

This data is microRNA, so maybe a different source could be better for use in alignment?
Perhaps from [[http://rfam.xfam.org/][Rfam]] or [[http://www.mirbase.org/][miRBase]]?

First we index our file of human transcripts from gencode.

#+begin_src bash

  # set up salmon index - using gencode v37 transcripts
  cd reference_genes
  salmon index -t gencode_human.v37.transcripts.fa -i gencode_v37_index --gencode
  cd ..
#+end_src

To do the aligmnent salmon need all the files from a sample on one line.
We have two reads, and therefore two files, for each sample.

#+begin_src bash

  # make .txt with the sample strings
  cd trimmed_manual
  command ls *.fq.gz | while read file;do echo $file | cut -dR -f1 >> samples.txt; done
#+end_src

Then we quantify our reads.

#+begin_src bash

  # get a list of unique sample file strings
  SAMPLE=$(cat samples.txt | sort | uniq)
  echo $SAMPLE
  # loop over sample files with salmon
  for i in ${SAMPLE}
  do
      salmon quant -i ../reference_genes/gencode_v37_index -l A -o ${i} -r ${i}*
  done

  # check that we have 17 directories as we expect
  ls -d *L001_ | wc -l
#+end_src

Check one of the output dirs

#+begin_src bash

    cd 1-16081_Nor_Cells_AGTCAAAT_L001_
    command ls -lh
    # check counts and quant
    cat lib_format_counts.json
    head quant.sf
  # check mapping rate
  grep -i 'mapping rate' logs/salmon_quant.log
    cd ..
#+end_src

** Prep for downstream analysis

We'll be using R for more downstream analysis, and we can do some prep to make life easier.

#+begin_src bash

  # get ensamble gene and transcript ids
  grep -P -o 'ENST\d{11}' ../reference_genes/gencode_human.v37.transcripts.fa > enst.txt
  grep -P -o 'ENSG\d{11}' ../reference_genes/gencode_human.v37.transcripts.fa > ensg.txt
#+end_src

#+begin_src bash

  # check
  head enst.txt
  paste -d ',' enst.txt ensg.txt | head
  # past gene and transcipt ids
  paste -d ',' enst.txt ensg.txt > ../../git_work/RNA-seq/ev_rna_seq_mairead_2021/gene_map.csv
#+end_src

#+RESULTS:
:results:

(rna_seq) [mateus@dell-xps159570 trimmed_manual]$ ENST00000456328
ENST00000450305
ENST00000488147
ENST00000619216
ENST00000473358
ENST00000469289
ENST00000607096
ENST00000417324
ENST00000461467
ENST00000606857
ENST00000456328,ENSG00000223972
ENST00000450305,ENSG00000223972
ENST00000488147,ENSG00000227232
ENST00000619216,ENSG00000278267
ENST00000473358,ENSG00000243485
ENST00000469289,ENSG00000243485
ENST00000607096,ENSG00000284332
ENST00000417324,ENSG00000237613
ENST00000461467,ENSG00000237613
ENST00000606857,ENSG00000268020
:end:
